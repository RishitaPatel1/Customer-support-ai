{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerSupportIntelligencePipeline:\n",
    "    def __init__(self, models_path='../models'):\n",
    "        self.models_path = models_path\n",
    "        self.classifier = None\n",
    "        self.eta_predictor = None\n",
    "        self.feature_extractor = None\n",
    "        self.sentiment_analyzer = None\n",
    "        self.response_generator = None\n",
    "        self.tag_generator = None\n",
    "        self.priority_adjuster = None\n",
    "        \n",
    "    def load_models(self):\n",
    "        try:\n",
    "            classifier_data = joblib.load(f'{self.models_path}/ticket_classifier.joblib')\n",
    "            self.classifier = classifier_data\n",
    "            \n",
    "            eta_data = joblib.load(f'{self.models_path}/eta_predictor.joblib')\n",
    "            self.eta_predictor = eta_data['best_model']\n",
    "            self.feature_extractor = eta_data['feature_extractor']\n",
    "            \n",
    "            self.sentiment_analyzer = joblib.load(f'{self.models_path}/sentiment_analyzer.joblib')\n",
    "            self.response_generator = joblib.load(f'{self.models_path}/response_generator.joblib')\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def initialize_components(self):\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        \n",
    "        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        class TagGenerator:\n",
    "            def __init__(self):\n",
    "                self.category_tags = {\n",
    "                    'billing': ['payment', 'invoice', 'charges', 'subscription', 'refund'],\n",
    "                    'technical': ['bug', 'error', 'crash', 'performance', 'login'],\n",
    "                    'general_inquiry': ['question', 'information', 'help', 'guidance'],\n",
    "                    'complaint': ['issue', 'problem', 'dissatisfied', 'frustrated'],\n",
    "                    'compliment': ['praise', 'satisfied', 'excellent', 'great'],\n",
    "                    'account': ['profile', 'settings', 'access', 'update']\n",
    "                }\n",
    "                \n",
    "                self.priority_tags = {\n",
    "                    'high': ['urgent', 'critical', 'immediate'],\n",
    "                    'medium': ['important', 'moderate'],\n",
    "                    'low': ['minor', 'routine']\n",
    "                }\n",
    "            \n",
    "            def generate_tags(self, text, category, priority):\n",
    "                tags = []\n",
    "                text_lower = text.lower()\n",
    "                \n",
    "                category_tag_pool = self.category_tags.get(category, ['general'])\n",
    "                priority_tag_pool = self.priority_tags.get(priority, ['standard'])\n",
    "                \n",
    "                for tag in category_tag_pool:\n",
    "                    if tag in text_lower:\n",
    "                        tags.append(tag)\n",
    "                        if len(tags) >= 2:\n",
    "                            break\n",
    "                \n",
    "                if len(tags) < 2:\n",
    "                    tags.extend(category_tag_pool[:2-len(tags)])\n",
    "                \n",
    "                tags.append(priority_tag_pool[0])\n",
    "                tags.append(category)\n",
    "                \n",
    "                return list(set(tags))[:4]\n",
    "        \n",
    "        class PriorityAdjuster:\n",
    "            def __init__(self):\n",
    "                self.urgency_keywords = {\n",
    "                    'critical': ['critical', 'emergency', 'urgent', 'asap', 'immediately'],\n",
    "                    'high': ['important', 'priority', 'soon', 'quickly', 'issue'],\n",
    "                    'medium': ['question', 'help', 'assistance', 'support'],\n",
    "                    'low': ['inquiry', 'information', 'when possible']\n",
    "                }\n",
    "            \n",
    "            def adjust_priority_with_eta(self, category, original_priority, eta_hours, text):\n",
    "                text_lower = text.lower()\n",
    "                \n",
    "                urgency_score = 0\n",
    "                for level, keywords in self.urgency_keywords.items():\n",
    "                    for keyword in keywords:\n",
    "                        if keyword in text_lower:\n",
    "                            if level == 'critical':\n",
    "                                urgency_score += 3\n",
    "                            elif level == 'high':\n",
    "                                urgency_score += 2\n",
    "                            elif level == 'medium':\n",
    "                                urgency_score += 1\n",
    "                \n",
    "                if eta_hours < 2 and urgency_score > 2:\n",
    "                    return 'high'\n",
    "                elif eta_hours < 8 and urgency_score > 1:\n",
    "                    return 'medium' if original_priority == 'low' else original_priority\n",
    "                elif eta_hours > 24:\n",
    "                    return 'low' if urgency_score == 0 else 'medium'\n",
    "                \n",
    "                return original_priority\n",
    "        \n",
    "        self.tag_generator = TagGenerator()\n",
    "        self.priority_adjuster = PriorityAdjuster()\n",
    "    \n",
    "    def process_single_ticket(self, ticket_text, ticket_id=None):\n",
    "        if ticket_id is None:\n",
    "            ticket_id = f\"TICKET_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        \n",
    "        result = {\n",
    "            'ticket_id': ticket_id,\n",
    "            'original_text': ticket_text,\n",
    "            'processing_timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            embeddings = self.embedder.encode([ticket_text])\n",
    "            \n",
    "            categories, priorities, cat_probas, pri_probas = self.classifier.predict(embeddings)\n",
    "            result['predicted_category'] = categories[0]\n",
    "            result['predicted_priority'] = priorities[0]\n",
    "            result['category_confidence'] = float(np.max(cat_probas[0]))\n",
    "            result['priority_confidence'] = float(np.max(pri_probas[0]))\n",
    "            \n",
    "            X_features = self.feature_extractor.transform(\n",
    "                [ticket_text], [categories[0]], [priorities[0]], embeddings\n",
    "            )\n",
    "            eta_prediction = self.eta_predictor.predict(X_features)\n",
    "            result['predicted_eta_hours'] = float(eta_prediction[0])\n",
    "            \n",
    "            if eta_prediction[0] < 2:\n",
    "                result['eta_category'] = 'immediate'\n",
    "            elif eta_prediction[0] < 8:\n",
    "                result['eta_category'] = 'same_day'\n",
    "            elif eta_prediction[0] < 24:\n",
    "                result['eta_category'] = 'next_day'\n",
    "            else:\n",
    "                result['eta_category'] = 'extended'\n",
    "            \n",
    "            adjusted_priority = self.priority_adjuster.adjust_priority_with_eta(\n",
    "                categories[0], priorities[0], eta_prediction[0], ticket_text\n",
    "            )\n",
    "            result['adjusted_priority'] = adjusted_priority\n",
    "            \n",
    "            sentiment = self.sentiment_analyzer.predict_sentiment_rule_based(ticket_text)\n",
    "            result['predicted_sentiment'] = sentiment\n",
    "            \n",
    "            response = self.response_generator.generate_response(\n",
    "                categories[0], sentiment, adjusted_priority, result['eta_category'], ticket_text\n",
    "            )\n",
    "            result['generated_response'] = response\n",
    "            \n",
    "            actions = self.response_generator.generate_follow_up_actions(\n",
    "                categories[0], adjusted_priority, sentiment\n",
    "            )\n",
    "            result['suggested_actions'] = actions\n",
    "            \n",
    "            tags = self.tag_generator.generate_tags(\n",
    "                ticket_text, categories[0], adjusted_priority\n",
    "            )\n",
    "            result['generated_tags'] = tags\n",
    "            \n",
    "            result['processing_status'] = 'success'\n",
    "            \n",
    "        except Exception as e:\n",
    "            result['processing_status'] = 'error'\n",
    "            result['error_message'] = str(e)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def process_batch(self, tickets_df):\n",
    "        results = []\n",
    "        \n",
    "        for idx, row in tickets_df.iterrows():\n",
    "            ticket_id = row.get('ticket_id', f'BATCH_{idx}')\n",
    "            ticket_text = row['text']\n",
    "            \n",
    "            result = self.process_single_ticket(ticket_text, ticket_id)\n",
    "            results.append(result)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def process_csv_file(self, input_path, output_path=None):\n",
    "        input_df = pd.read_csv(input_path)\n",
    "        \n",
    "        required_columns = ['text']\n",
    "        for col in required_columns:\n",
    "            if col not in input_df.columns:\n",
    "                raise ValueError(f\"Required column '{col}' not found in input CSV\")\n",
    "        \n",
    "        results_df = self.process_batch(input_df)\n",
    "        \n",
    "        if output_path:\n",
    "            results_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        return results_df\n",
    "\n",
    "pipeline = CustomerSupportIntelligencePipeline()\n",
    "pipeline.initialize_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tickets = [\n",
    "    {\n",
    "        'ticket_id': 'TEST_001',\n",
    "        'text': 'My credit card was charged twice for the same service this month'\n",
    "    },\n",
    "    {\n",
    "        'ticket_id': 'TEST_002', \n",
    "        'text': 'The application keeps crashing when I try to upload files, this is urgent'\n",
    "    },\n",
    "    {\n",
    "        'ticket_id': 'TEST_003',\n",
    "        'text': 'I love the new features you added, great work!'\n",
    "    },\n",
    "    {\n",
    "        'ticket_id': 'TEST_004',\n",
    "        'text': 'How do I change my password? I forgot the steps'\n",
    "    },\n",
    "    {\n",
    "        'ticket_id': 'TEST_005',\n",
    "        'text': 'This service is absolutely terrible, I want my money back immediately'\n",
    "    }\n",
    "]\n",
    "\n",
    "test_df = pd.DataFrame(test_tickets)\n",
    "\n",
    "processed_results = []\n",
    "for _, row in test_df.iterrows():\n",
    "    result = pipeline.process_single_ticket(row['text'], row['ticket_id'])\n",
    "    processed_results.append(result)\n",
    "\n",
    "test_results_df = pd.DataFrame(processed_results)\n",
    "test_results_df.to_csv('../outputs/pipeline_test_results.csv', index=False)\n",
    "\n",
    "pipeline_summary = {\n",
    "    'test_cases_processed': len(test_results_df),\n",
    "    'successful_predictions': len(test_results_df[test_results_df['processing_status'] == 'success']),\n",
    "    'category_distribution': test_results_df['predicted_category'].value_counts().to_dict(),\n",
    "    'priority_distribution': test_results_df['adjusted_priority'].value_counts().to_dict(),\n",
    "    'sentiment_distribution': test_results_df['predicted_sentiment'].value_counts().to_dict(),\n",
    "    'eta_distribution': test_results_df['eta_category'].value_counts().to_dict(),\n",
    "    'average_processing_confidence': {\n",
    "        'category': float(test_results_df['category_confidence'].mean()),\n",
    "        'priority': float(test_results_df['priority_confidence'].mean())\n",
    "    },\n",
    "    'average_eta_hours': float(test_results_df['predicted_eta_hours'].mean())\n",
    "}\n",
    "\n",
    "with open('../outputs/pipeline_summary.json', 'w') as f:\n",
    "    json.dump(pipeline_summary, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = {\n",
    "    'version': '1.0',\n",
    "    'creation_date': datetime.now().isoformat(),\n",
    "    'components': {\n",
    "        'ticket_classifier': 'RandomForest + LogisticRegression',\n",
    "        'eta_predictor': 'Ensemble Regression Models',\n",
    "        'sentiment_analyzer': 'Rule-based + TextBlob',\n",
    "        'response_generator': 'Template-based with context awareness',\n",
    "        'embeddings': 'SentenceTransformer (all-MiniLM-L6-v2)'\n",
    "    },\n",
    "    'supported_categories': ['billing', 'technical', 'general_inquiry', 'complaint', 'compliment', 'account'],\n",
    "    'supported_priorities': ['high', 'medium', 'low'],\n",
    "    'supported_sentiments': ['positive', 'negative', 'neutral'],\n",
    "    'eta_categories': ['immediate', 'same_day', 'next_day', 'extended'],\n",
    "    'input_format': 'CSV with text column',\n",
    "    'output_format': 'Enhanced CSV with predictions and responses'\n",
    "}\n",
    "\n",
    "with open('../models/pipeline_config.json', 'w') as f:\n",
    "    json.dump(pipeline_config, f, indent=2)\n",
    "\n",
    "joblib.dump(pipeline, '../models/complete_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demo-csv-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = {\n",
    "    'ticket_id': ['DEMO_001', 'DEMO_002', 'DEMO_003'],\n",
    "    'text': [\n",
    "        'I need help with my account settings, cannot access my profile',\n",
    "        'Your new update is amazing! Love the improved interface',\n",
    "        'Critical system error - production server is down, need immediate assistance'\n",
    "    ]\n",
    "}\n",
    "\n",
    "demo_df = pd.DataFrame(demo_data)\n",
    "demo_df.to_csv('../data/demo_input.csv', index=False)\n",
    "\n",
    "demo_output = pipeline.process_csv_file('../data/demo_input.csv', '../outputs/demo_processed_output.csv')\n",
    "\n",
    "demo_analysis = {\n",
    "    'input_tickets': len(demo_df),\n",
    "    'processed_successfully': len(demo_output[demo_output['processing_status'] == 'success']),\n",
    "    'processing_time': 'Real-time (< 1 second per ticket)',\n",
    "    'sample_results': demo_output[['ticket_id', 'predicted_category', 'adjusted_priority', \n",
    "                                  'predicted_sentiment', 'eta_category']].to_dict('records')\n",
    "}\n",
    "\n",
    "with open('../outputs/demo_analysis.json', 'w') as f:\n",
    "    json.dump(demo_analysis, f, indent=2)"
   ]
  }
 ],\n "metadata": {\n  "kernelspec": {\n   "display_name": "Python 3",\n   "language": "python",\n   "name": "python3"\n  },\n  "language_info": {\n   "codemirror_mode": {\n    "name": "ipython",\n    "version": 3\n   },\n   "file_extension": ".py",\n   "mimetype": "text/x-python",\n   "name": "python",\n   "nbconvert_exporter": "python",\n   "pygments_lexer": "ipython3",\n   "version": "3.8.0"\n  }\n },\n "nbformat": 4,\n "nbformat_minor": 5\n}