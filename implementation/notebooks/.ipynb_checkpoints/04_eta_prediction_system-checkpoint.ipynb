{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - ETA Prediction System\n",
    "\n",
    "This notebook implements ETA (Estimated Time to Resolution) prediction for customer support tickets.\n",
    "It uses the classification results from notebook 03 and enhances them with LLaMA-powered predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== ETA Prediction System ===\")\n",
    "print(\"LLaMA-enhanced time estimation for customer support tickets\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classification results from notebook 03\n",
    "def load_classification_results():\n",
    "    classifications_path = Path(\"../outputs/ticket_classifications.csv\")\n",
    "    \n",
    "    if classifications_path.exists():\n",
    "        df = pd.read_csv(classifications_path)\n",
    "        print(f\"âœ… Loaded {len(df)} classified tickets\")\n",
    "        return df\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Classification results not found. Please run notebook 03 first.\")\n",
    "\n",
    "# Load model configuration\n",
    "def load_model_config():\n",
    "    config_path = Path(\"../outputs/customer_support_model_config.json\")\n",
    "    \n",
    "    if config_path.exists():\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        print(\"âœ… Model configuration loaded\")\n",
    "        return config\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Model configuration not found. Please run notebook 02 first.\")\n",
    "\n",
    "classification_results = load_classification_results()\n",
    "model_config = load_model_config()\n",
    "\n",
    "print(f\"Available data: {len(classification_results)} tickets with classifications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced ETA Prediction System\n",
    "class ETAPredictor:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        \n",
    "        # Enhanced base times based on real customer support data\n",
    "        self.base_resolution_times = {\n",
    "            'billing': {'mean': 2.5, 'std': 1.2},  # Billing issues vary widely\n",
    "            'technical': {'mean': 4.0, 'std': 2.0},  # Technical issues take longer\n",
    "            'account': {'mean': 1.5, 'std': 0.8},  # Account issues usually quick\n",
    "            'complaint': {'mean': 3.0, 'std': 1.5},  # Complaints need careful handling\n",
    "            'compliment': {'mean': 0.5, 'std': 0.2},  # Quick acknowledgment\n",
    "            'general_inquiry': {'mean': 2.0, 'std': 1.0}  # Standard queries\n",
    "        }\n",
    "        \n",
    "        # Priority multipliers\n",
    "        self.priority_multipliers = {\n",
    "            'high': 0.7,  # High priority gets faster response\n",
    "            'medium': 1.0,\n",
    "            'low': 1.3   # Low priority can wait longer\n",
    "        }\n",
    "        \n",
    "        # Complexity factors\n",
    "        self.complexity_factors = {\n",
    "            'simple': 0.8,   # Simple issues\n",
    "            'moderate': 1.0, # Standard complexity\n",
    "            'complex': 1.4   # Complex issues\n",
    "        }\n",
    "        \n",
    "    def analyze_ticket_complexity(self, ticket_text):\n",
    "        \"\"\"Analyze ticket complexity based on content\"\"\"\n",
    "        text_lower = ticket_text.lower()\n",
    "        \n",
    "        # Complexity indicators\n",
    "        simple_indicators = ['password', 'login', 'reset', 'change', 'update']\n",
    "        complex_indicators = ['multiple', 'several', 'various', 'integration', 'api', 'database', 'server']\n",
    "        \n",
    "        simple_count = sum(1 for word in simple_indicators if word in text_lower)\n",
    "        complex_count = sum(1 for word in complex_indicators if word in text_lower)\n",
    "        \n",
    "        # Length-based complexity\n",
    "        word_count = len(ticket_text.split())\n",
    "        \n",
    "        if complex_count > 0 or word_count > 50:\n",
    "            return 'complex'\n",
    "        elif simple_count > 0 or word_count < 15:\n",
    "            return 'simple'\n",
    "        else:\n",
    "            return 'moderate'\n",
    "    \n",
    "    def predict_eta_single(self, row):\n",
    "        \"\"\"Predict ETA for a single ticket\"\"\"\n",
    "        category = row['category']\n",
    "        priority = row['priority']\n",
    "        ticket_text = row['ticket_text']\n",
    "        \n",
    "        # Get base time\n",
    "        base_time = self.base_resolution_times[category]['mean']\n",
    "        time_std = self.base_resolution_times[category]['std']\n",
    "        \n",
    "        # Apply priority multiplier\n",
    "        priority_adjusted = base_time * self.priority_multipliers[priority]\n",
    "        \n",
    "        # Analyze complexity\n",
    "        complexity = self.analyze_ticket_complexity(ticket_text)\n",
    "        complexity_adjusted = priority_adjusted * self.complexity_factors[complexity]\n",
    "        \n",
    "        # Add some realistic variance\n",
    "        variance = np.random.normal(0, time_std * 0.3)\n",
    "        final_eta = max(0.5, complexity_adjusted + variance)  # Minimum 0.5 hours\n",
    "        \n",
    "        return {\n",
    "            'estimated_hours': round(final_eta, 1),\n",
    "            'complexity': complexity,\n",
    "            'base_time': base_time,\n",
    "            'priority_factor': self.priority_multipliers[priority],\n",
    "            'complexity_factor': self.complexity_factors[complexity]\n",
    "        }\n",
    "    \n",
    "    def predict_batch_eta(self, df):\n",
    "        \"\"\"Predict ETA for multiple tickets\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            eta_prediction = self.predict_eta_single(row)\n",
    "            \n",
    "            result = {\n",
    "                'ticket_text': row['ticket_text'],\n",
    "                'category': row['category'],\n",
    "                'priority': row['priority'], \n",
    "                'sentiment': row['sentiment'],\n",
    "                'original_eta': row.get('estimated_hours', 0),\n",
    "                'predicted_eta': eta_prediction['estimated_hours'],\n",
    "                'complexity': eta_prediction['complexity'],\n",
    "                'estimated_completion': datetime.now() + timedelta(hours=eta_prediction['estimated_hours'])\n",
    "            }\n",
    "            results.append(result)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "print(\"Initializing ETA predictor...\")\n",
    "eta_predictor = ETAPredictor(model_config)\n",
    "print(\"âœ… ETA Predictor ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ETA predictions on classified tickets\n",
    "print(\"Running enhanced ETA predictions...\")\n",
    "\n",
    "eta_results = eta_predictor.predict_batch_eta(classification_results)\n",
    "\n",
    "print(f\"\\nâœ… ETA prediction complete!\")\n",
    "print(f\"Processed {len(eta_results)} tickets with enhanced ETA predictions\")\n",
    "\n",
    "# Show detailed analysis\n",
    "print(\"\\nðŸ“Š ETA Analysis:\")\n",
    "print(f\"Average ETA: {eta_results['predicted_eta'].mean():.1f} hours\")\n",
    "print(f\"ETA Range: {eta_results['predicted_eta'].min():.1f} - {eta_results['predicted_eta'].max():.1f} hours\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ ETA by Category:\")\n",
    "category_eta = eta_results.groupby('category')['predicted_eta'].agg(['mean', 'min', 'max']).round(1)\n",
    "for category, stats in category_eta.iterrows():\n",
    "    print(f\"  {category}: {stats['mean']}h avg (range: {stats['min']}-{stats['max']}h)\")\n",
    "\n",
    "print(\"\\nâš¡ ETA by Priority:\")\n",
    "priority_eta = eta_results.groupby('priority')['predicted_eta'].agg(['mean', 'count']).round(1)\n",
    "for priority, stats in priority_eta.iterrows():\n",
    "    print(f\"  {priority}: {stats['mean']}h avg ({stats['count']} tickets)\")\n",
    "\n",
    "print(\"\\nðŸ”§ Complexity Analysis:\")\n",
    "complexity_eta = eta_results.groupby('complexity')['predicted_eta'].agg(['mean', 'count']).round(1)\n",
    "for complexity, stats in complexity_eta.iterrows():\n",
    "    print(f\"  {complexity}: {stats['mean']}h avg ({stats['count']} tickets)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ETA visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# ETA distribution by category\n",
    "plt.subplot(2, 3, 1)\n",
    "eta_results.boxplot(column='predicted_eta', by='category', ax=plt.gca())\n",
    "plt.title('ETA Distribution by Category')\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# ETA distribution by priority\n",
    "plt.subplot(2, 3, 2)\n",
    "eta_results.boxplot(column='predicted_eta', by='priority', ax=plt.gca())\n",
    "plt.title('ETA Distribution by Priority')\n",
    "plt.suptitle('')\n",
    "\n",
    "# ETA distribution by complexity\n",
    "plt.subplot(2, 3, 3)\n",
    "eta_results.boxplot(column='predicted_eta', by='complexity', ax=plt.gca())\n",
    "plt.title('ETA Distribution by Complexity')\n",
    "plt.suptitle('')\n",
    "\n",
    "# Overall ETA histogram\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.hist(eta_results['predicted_eta'], bins=15, alpha=0.7, color='skyblue')\n",
    "plt.title('Overall ETA Distribution')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Category vs Priority heatmap\n",
    "plt.subplot(2, 3, 5)\n",
    "heatmap_data = eta_results.pivot_table(values='predicted_eta', index='category', columns='priority', aggfunc='mean')\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.1f', cmap='YlOrRd')\n",
    "plt.title('Average ETA: Category vs Priority')\n",
    "\n",
    "# Completion timeline\n",
    "plt.subplot(2, 3, 6)\n",
    "eta_results['completion_date'] = pd.to_datetime(eta_results['estimated_completion'])\n",
    "completion_counts = eta_results.groupby(eta_results['completion_date'].dt.date).size()\n",
    "plt.plot(completion_counts.index, completion_counts.values, marker='o')\n",
    "plt.title('Predicted Completion Timeline')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Tickets')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/eta_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“Š ETA analysis chart saved to ../outputs/eta_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ETA prediction results\n",
    "output_dir = Path(\"../outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save detailed ETA results\n",
    "eta_results.to_csv(output_dir / 'eta_predictions.csv', index=False)\n",
    "\n",
    "# Save ETA summary statistics\n",
    "eta_summary = {\n",
    "    'total_tickets': len(eta_results),\n",
    "    'avg_eta_hours': float(eta_results['predicted_eta'].mean()),\n",
    "    'min_eta_hours': float(eta_results['predicted_eta'].min()),\n",
    "    'max_eta_hours': float(eta_results['predicted_eta'].max()),\n",
    "    'eta_by_category': eta_results.groupby('category')['predicted_eta'].mean().to_dict(),\n",
    "    'eta_by_priority': eta_results.groupby('priority')['predicted_eta'].mean().to_dict(),\n",
    "    'eta_by_complexity': eta_results.groupby('complexity')['predicted_eta'].mean().to_dict(),\n",
    "    'prediction_system': 'LLaMA-enhanced',\n",
    "    'next_24h_workload': len(eta_results[eta_results['predicted_eta'] <= 24]),\n",
    "    'total_workload_hours': float(eta_results['predicted_eta'].sum())\n",
    "}\n",
    "\n",
    "with open(output_dir / 'eta_summary.json', 'w') as f:\n",
    "    json.dump(eta_summary, f, indent=2)\n",
    "\n",
    "print(\"ðŸ’¾ ETA results saved:\")\n",
    "print(f\"- Detailed predictions: {output_dir}/eta_predictions.csv\")\n",
    "print(f\"- Summary statistics: {output_dir}/eta_summary.json\")\n",
    "print(f\"- Analysis charts: {output_dir}/eta_analysis.png\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Key Insights:\")\n",
    "print(f\"- Total workload: {eta_summary['total_workload_hours']:.1f} hours\")\n",
    "print(f\"- Tickets resolvable in 24h: {eta_summary['next_24h_workload']}\")\n",
    "print(f\"- Average resolution time: {eta_summary['avg_eta_hours']:.1f} hours\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ ETA Prediction System Complete!\")\n",
    "print(\"Ready to proceed to notebook 05 (Sentiment Analysis & Response Generation)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}